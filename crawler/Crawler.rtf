{\rtf1\ansi\ansicpg1252\cocoartf2577
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red191\green100\blue38;\red32\green32\blue32;\red153\green168\blue186;
\red88\green118\blue71;\red86\green132\blue173;\red152\green54\blue29;\red117\green114\blue185;}
{\*\expandedcolortbl;;\csgenericrgb\c74902\c39216\c14902;\csgenericrgb\c12549\c12549\c12549;\csgenericrgb\c60000\c65882\c72941;
\csgenericrgb\c34510\c46275\c27843;\csgenericrgb\c33725\c51765\c67843;\csgenericrgb\c59608\c21176\c11373;\csgenericrgb\c45882\c44706\c72549;}
\paperw11900\paperh16840\margl1440\margr1440\vieww33400\viewh21000\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs26 \cf2 \cb3 import \cf4 selenium\
\cf2 from \cf4 selenium \cf2 import \cf4 webdriver\
\cf2 import \cf4 pandas \cf2 as \cf4 pd\
\cf2 import \cf4 time\
\cf2 import \cf4 math\
\
keyword = \cf5 "insurance"\
\cf4 i = \cf6 1\
\cf4 output = []\
page_num = \cf6 0\
\cf4 driver = webdriver.Chrome(\cf7 executable_path\cf4 =\cf5 '/Users/masterthesis/Downloads/chromedriver'\cf4 )\
driver.get(\
        \cf5 "https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=dl&field1=Keyword&text1=" \cf4 +\
        keyword + \cf5 "&field2=Abstract&text2=" \cf4 + keyword + \cf5 "&startPage="\
        \cf4 + \cf8 str\cf4 (page_num) + \cf5 "&pageSize=50"\cf4 )\
\cf8 print\cf4 (driver.title)\
num_of_articles = driver.find_element_by_class_name(\cf5 "hitsLength"\cf4 ).text\
num_of_articles = num_of_articles.replace(\cf5 ','\cf2 , \cf5 ''\cf4 )\
max_page_num = math.ceil(\cf8 int\cf4 (num_of_articles)/\cf6 50\cf4 )\
max_page_num_temp = max_page_num\
\cf8 print\cf4 (\cf5 "Total # of pages = "\cf2 , \cf4 max_page_num)\
\cf2 if \cf4 max_page_num > \cf6 10\cf4 :\
    max_page_num = \cf6 10\
\cf8 print\cf4 (\cf5 "# of pages will be crawled = "\cf2 , \cf4 max_page_num)\
\cf2 if \cf4 max_page_num_temp > \cf6 10\cf4 :\
        \cf8 print\cf4 (\cf5 '# of articles will be crawled = 1000'\cf4 )\
\cf2 else\cf4 :\
        \cf8 print\cf4 (\cf5 '# of articles will be crawled = '\cf2 , \cf4 num_of_articles)\
\cf8 print\cf4 (\cf5 "---------------------------------------------------------------------------------------------------"\cf4 )\
\
\cf2 for \cf4 j \cf2 in \cf8 range\cf4 (\cf6 1\cf2 , \cf4 max_page_num + \cf6 1\cf4 ):\
        driver.get(\
                \cf5 "https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=dl&field1=Keyword&text1=" \cf4 +\
                keyword + \cf5 "&field2=Abstract&text2=" \cf4 + keyword + \cf5 "&startPage="\
                \cf4 + \cf8 str\cf4 (page_num) + \cf5 "&pageSize=50"\cf4 )\
        articles = driver.find_elements_by_class_name(\cf5 "issue-item__content-right"\cf4 )\
        \cf2 for \cf4 article \cf2 in \cf4 articles:\
                \cf2 try\cf4 :\
                        title = driver.find_element_by_xpath(\cf5 '//*[@id="pb-page-content"]/div/main/div[1]/div/div[2]/div/ul/li['\
                                                             \cf4 + \cf8 str\cf4 (i) + \cf5 ']/div/div[2]/div/h5/span/a'\cf4 )\
                        title_text = title.text\
                        \cf8 print\cf4 (title_text)\
\
                        title.click()\
                        time.sleep(\cf6 2\cf4 )\
                \cf2 except\cf4 :\
                        title = \cf2 None\
\
\
\
                \cf4 abstract = driver.find_element_by_css_selector(\cf5 '.abstractInFull p'\cf4 )\
                abstract_text = abstract.text\
                \cf8 print\cf4 (abstract_text)\
\
                downloads = driver.find_element_by_xpath(\
                        \cf5 '//*[@id="pb-page-content"]/div/main/div[2]/article/div[1]/div[2]/div/div[5]/div/div[1]/div/ul/li[2]/span/span'\cf4 )\
                downloads_text = downloads.text\
                \cf8 print\cf4 (downloads_text)\
\
                citations = driver.find_element_by_xpath(\
                        \cf5 '//*[@id="pb-page-content"]/div/main/div[2]/article/div[1]/div[2]/div/div[5]/div/div[1]/div/ul/li[1]/span/span[1]'\cf4 )\
                citations_text = citations.text\
                \cf8 print\cf4 (citations_text)\
\
                date = driver.find_element_by_xpath(\
                        \cf5 '//*[@id="pb-page-content"]/div/main/div[2]/article/div[1]/div[2]/div/div[4]/div/span[2]/span'\cf4 )\
                date_text = date.text\
                \cf8 print\cf4 (date_text)\
\
                \cf2 try\cf4 :\
\
                        author_1 = driver.find_element_by_xpath(\cf5 "/html/body/div[1]/div/main/div[2]/article/div[1]/div[2]/div/div[3]/div/ul/li[2]/a/span/div/span/span"\cf4 )\
                        author_1_text = author_1.text\
                        \cf8 print\cf4 (author_1_text)\
                \cf2 except\cf4 :\
                        author_1 = \cf2 None\
\
                try\cf4 :\
\
                        author_2 = driver.find_element_by_xpath(\cf5 "/html/body/div[1]/div/main/div[2]/article/div[1]/div[2]/div/div[3]/div/ul/li[3]/a/span/div/span/span"\cf4 )\
                        author_2_text = author_2.text\
                        \cf8 print\cf4 (author_2_text)\
                \cf2 except\cf4 :\
                        author_2 = \cf2 None\
                        \cf4 author_2_text = \cf2 None\
\
                try\cf4 :\
                        link = driver.find_element_by_xpath(\
                                \cf5 '//*[@id="pb-page-content"]/div/main/div[2]/article/div[1]/div[2]/div/div[4]/div/span/a'\cf4 )\
                        link_text = link.text\
                        \cf8 print\cf4 (link_text)\
                \cf2 except\cf4 :\
                        link = \cf2 None\
\
                \cf4 temp = \{\cf5 'Title'\cf4 : title_text\cf2 ,\
                        \cf5 'total_downloads'\cf4 : downloads_text\cf2 ,\
                        \cf5 'total_citations'\cf4 : citations_text\cf2 ,\
                        \cf5 'date'\cf4 : date_text\cf2 ,\
                        \cf5 'author_1'\cf4 : author_1_text\cf2 ,\
                        \cf5 'author_2'\cf4 : author_2_text\cf2 ,\
                        \cf5 'link'\cf4 : link_text\cf2 ,\
                        \cf5 'abstract'\cf4 : abstract_text\}\
                output.append(temp)\
\
                driver.back()\
                time.sleep(\cf6 2\cf4 )\
                \cf8 print\cf4 (\cf5 "Total number of articles in this page: "\cf2 , \cf8 len\cf4 (articles))\
                \cf8 print\cf4 (\cf5 "Scraping article # "\cf2 , \cf4 i)\
                \cf8 print\cf4 (\cf5 "---------------------------------------------------------------------------------------------------"\cf4 )\
                \cf2 if \cf4 i <= \cf8 len\cf4 (articles):\
                        i = i + \cf6 1\
                \cf2 else\cf4 :\
                        \cf2 break\
        \cf4 i = \cf6 1\
        \cf4 page_num = page_num + \cf6 1\
\
\cf4 output = pd.DataFrame(output)\
output[\cf5 'date'\cf4 ] = output.date.str.replace(\cf5 ','\cf2 , \cf5 ''\cf4 )\
output[\cf5 'date'\cf4 ] = pd.to_datetime(output[\cf5 'date'\cf4 ])\
output[\cf5 'total_citations'\cf4 ] = output.total_citations.str.replace(\cf5 ','\cf2 , \cf5 ''\cf4 )\
output[\cf5 'total_citations'\cf4 ] = output[\cf5 'total_citations'\cf4 ].astype(\cf5 'int'\cf4 )\
output[\cf5 'total_downloads'\cf4 ] = output.total_downloads.str.replace(\cf5 ','\cf2 , \cf5 ''\cf4 )\
output[\cf5 'total_downloads'\cf4 ] = output[\cf5 'total_downloads'\cf4 ].astype(\cf5 'int'\cf4 )\
output.to_excel(\cf5 "output.xlsx"\cf2 , \cf7 index\cf4 =\cf2 False\cf4 )\
\
}